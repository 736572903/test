#topic
kafka.topic=test
#broker.list
kafka.metadata.broker.list=192.168.0.119:9092;192.168.0.117:9092;192.168.0.118:9092

#---------------------生产者配置------------------------
#生产方式，1.sync 生产者生产消息，会立即发送到某个分区 ；2.async 生产者生产消息，不会立即发送到某个分区，而会先存在一个缓存区
kafka.producer.type=sync
#0:表示producer生产的消息，被topic的partition的leader接收，就返回成功，不管是否存储到kafka
#1:表示producer生产的消息，被topic的partition的leader接收且存储到其服务器的replica备份上，就返回成功，但是如果此时leader挂了，则消息丢失，因为其他的服务器replica备份无此消息
#all或者-1:表示producer生产的消息，被leader接收且存储在leader服务器的replica上，并且该partition的其他replica也存储完成，则返回成功
kafka.request.required.acks=all
#序列化
kafka.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.value.serializer=org.apache.kafka.common.serialization.StringSerializer
#batch.size是producer批量发送的基本单位，默认是16384Bytes，即16kB；下面两个参数满足其中之一就进行发送
kafka.batch.size=16384
#lingger.ms是sender线程在检查batch是否ready时候,默认大小是0ms。不是立即发送一条记录，producer将会等待给定的延迟时间以允许其他消息记录发送
kafka.lingger.ms=500000
#0当queue满时丢掉，负值是queue满时block,正值是queue满时block相应的时间，仅仅for asyc,如果想要保证异步生产消息尽量不丢失，设置为负值，缓冲区满了，queue满了会一直阻塞
queue.enqueue.timeout.ms=-1
#---------------------消费者配置------------------------
#consumer组的组id，一个consumer组含有多个consumer，1个partition对应一个consumer，一个consumer可以对应多个partition
kafka.group.id=test-consumer-group
#反序列化
kafka.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#消费者取到了，立即提交成功，但是当取到后挂了，这个消息就没了
#kafka.enable.auto.commit=true
kafka.enable.auto.commit=false
#自动提交offset到zookeeper的时间间隔
kafka.auto.commit.interval.ms=1000
#如果其超时，将会可能触发rebalance并认为已经死去
kafka.session.timeout.ms=3000
#分区策略range和roundrobin
kafka.partition.assignment.strategy=range